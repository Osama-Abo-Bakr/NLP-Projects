{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986f76e0",
   "metadata": {},
   "source": [
    "# Main Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea2cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string, nltk\n",
    "\n",
    "# Data Preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Building Deep Learning Model\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import tensorflow.keras as k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df739d1",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76595b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>marathi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>I just sold my car.</td>\n",
       "      <td>मी आत्ताच माझी गाडी विकून टाकली.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>I just took a bath.</td>\n",
       "      <td>मी आत्ताच आंघोळ केली.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>I just want to die.</td>\n",
       "      <td>मला फक्त मरायचं आहे.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>I knew you'd laugh.</td>\n",
       "      <td>मला माहीत होतं की तू हसशील.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>I knew you'd laugh.</td>\n",
       "      <td>तू हसशील हे मला माहीत होतं.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   english                           marathi\n",
       "10000  I just sold my car.  मी आत्ताच माझी गाडी विकून टाकली.\n",
       "10001  I just took a bath.             मी आत्ताच आंघोळ केली.\n",
       "10002  I just want to die.              मला फक्त मरायचं आहे.\n",
       "10003  I knew you'd laugh.       मला माहीत होतं की तू हसशील.\n",
       "10004  I knew you'd laugh.       तू हसशील हे मला माहीत होतं."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(r\"D:\\Courses language programming\\9_Big Projects\\14 - Machine Translation\\mar-eng\\mar.txt\")\n",
    "data.columns = [\"english\", \"marathi\", \"x\"]\n",
    "data = data.drop(columns=\"x\", axis=1)\n",
    "data = data.iloc[10000:20000]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea40a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b982e5c",
   "metadata": {},
   "source": [
    "# Building Encoder input :: English Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6230ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Max Length of English Word is -->  7\n",
      "The Shape Of Encoder Input is -->  (10000, 7)\n",
      "The Number of English Word is -->  2433\n"
     ]
    }
   ],
   "source": [
    "eng_lines = []\n",
    "\n",
    "for line in data.english:\n",
    "    eng_lines.append(line)\n",
    "    \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(eng_lines)\n",
    "eng_seq = tokenizer.texts_to_sequences(eng_lines)\n",
    "max_eng = max([len(word) for word in eng_seq])\n",
    "\n",
    "print(\"The Max Length of English Word is --> \", max_eng)\n",
    "english_padded = pad_sequences(eng_seq, maxlen=max_eng, padding=\"post\")\n",
    "english_padded_arr = np.array(english_padded)\n",
    "\n",
    "print(\"The Shape Of Encoder Input is --> \", english_padded_arr.shape)\n",
    "\n",
    "eng_word_dict = tokenizer.word_index\n",
    "num_eng_words = len(eng_word_dict) + 1\n",
    "\n",
    "print(\"The Number of English Word is --> \",  num_eng_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba6e4c",
   "metadata": {},
   "source": [
    "# Building Decoder Input :: Marathi  Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f640a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Max Length of Marathi Word is -->  11\n",
      "The Shape Of Encoder Input is -->  (10000, 11)\n",
      "The Number of Marathi Word is -->  4833\n"
     ]
    }
   ],
   "source": [
    "mar_lines = []\n",
    "\n",
    "for line in data.marathi:\n",
    "    mar_lines.append(\"<START>\" + line + \"<END>\")\n",
    "    \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(mar_lines)\n",
    "mar_seq = tokenizer.texts_to_sequences(mar_lines)\n",
    "\n",
    "max_mar = max([len(word) for word in mar_seq])\n",
    "print(\"The Max Length of Marathi Word is --> \", max_mar)\n",
    "\n",
    "marathi_padded = pad_sequences(mar_seq, maxlen=max_mar, padding=\"post\")\n",
    "marathi_padded_arr = np.array(marathi_padded)\n",
    "\n",
    "print(\"The Shape Of Encoder Input is --> \", marathi_padded_arr.shape)\n",
    "\n",
    "mar_word_dict = tokenizer.word_index\n",
    "num_mar_words = len(mar_word_dict) + 1\n",
    "\n",
    "print(\"The Number of Marathi Word is --> \",  num_mar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867344a",
   "metadata": {},
   "source": [
    "# Building Decoder :: Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3895fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output_data = []\n",
    "\n",
    "for token in mar_seq:\n",
    "    decoder_output_data.append(token[1:])\n",
    "\n",
    "marathi_padded_output = pad_sequences(decoder_output_data, maxlen=max_mar, padding=\"post\")\n",
    "onehot_mar_lines = to_categorical(marathi_padded_output, num_mar_words)\n",
    "\n",
    "decoder_output_data = np.array(onehot_mar_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057d74b",
   "metadata": {},
   "source": [
    "# -- Building LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "627d0c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 256)            622848    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 256)            1237248   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 128),                197120    ['embedding[0][0]']           \n",
      "                              (None, 128),                                                        \n",
      "                              (None, 128)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 128),          197120    ['embedding_1[0][0]',         \n",
      "                              (None, 128),                           'lstm[0][1]',                \n",
      "                              (None, 128)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 4833)           623457    ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2877793 (10.98 MB)\n",
      "Trainable params: 2877793 (10.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = Input(shape=(None, ))\n",
    "encoder_embeding = Embedding(num_eng_words, 256 ,mask_zero=True)(encoder_input)\n",
    "encoder_output, state_h, state_c = LSTM(128, return_state=True)(encoder_embeding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_input = Input(shape=(None, ))\n",
    "decoder_embeding = Embedding(num_mar_words, 256, mask_zero=True)(decoder_input)\n",
    "decoder_lstm = LSTM(128, return_state=True, return_sequences=True)\n",
    "decoder_output, _, _ = decoder_lstm(decoder_embeding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_mar_words, activation=\"softmax\")\n",
    "output = decoder_dense(decoder_output)\n",
    "\n",
    "model = Model([encoder_input, decoder_input], output)\n",
    "\n",
    "model.compile(optimizer=k.optimizers.RMSprop(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e9bb07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 13s 211ms/step - loss: 7.6425 - accuracy: 0.1599\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 5.3471 - accuracy: 0.1679\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 5.0364 - accuracy: 0.2043\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 4.8213 - accuracy: 0.2570\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 4.6448 - accuracy: 0.3167\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 4.4854 - accuracy: 0.3515\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 4.3775 - accuracy: 0.3546\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 4.3172 - accuracy: 0.3564\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 7s 197ms/step - loss: 4.2758 - accuracy: 0.3562\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 7s 196ms/step - loss: 4.2406 - accuracy: 0.3568\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 4.2054 - accuracy: 0.3588\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 4.1691 - accuracy: 0.3621\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 4.1287 - accuracy: 0.3655\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 4.0931 - accuracy: 0.3690\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 7s 197ms/step - loss: 4.0592 - accuracy: 0.3741\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 4.0264 - accuracy: 0.3810\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 7s 196ms/step - loss: 3.9915 - accuracy: 0.3865\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 3.9574 - accuracy: 0.3891\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 3.9238 - accuracy: 0.3920\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 3.8897 - accuracy: 0.3943\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 3.8539 - accuracy: 0.3971\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 3.8191 - accuracy: 0.4001\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 3.7842 - accuracy: 0.4045\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 7s 197ms/step - loss: 3.7476 - accuracy: 0.4087\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 3.7111 - accuracy: 0.4117\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 3.6784 - accuracy: 0.4163\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 3.6430 - accuracy: 0.4199\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 3.6100 - accuracy: 0.4233\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 3.5779 - accuracy: 0.4274\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 3.5423 - accuracy: 0.4316\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 3.5124 - accuracy: 0.4355\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 3.4783 - accuracy: 0.4402\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 3.4468 - accuracy: 0.4437\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 3.4155 - accuracy: 0.4468\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 3.3834 - accuracy: 0.4504\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 3.3532 - accuracy: 0.4530\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 3.3217 - accuracy: 0.4568\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 3.2905 - accuracy: 0.4607\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 3.2614 - accuracy: 0.4639\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 3.2304 - accuracy: 0.4668\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 3.2027 - accuracy: 0.4703\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 7s 197ms/step - loss: 3.1713 - accuracy: 0.4751\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 3.1444 - accuracy: 0.4781\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 3.1138 - accuracy: 0.4814\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 3.0866 - accuracy: 0.4860\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 3.0563 - accuracy: 0.4897\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 3.0282 - accuracy: 0.4923\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 2.9980 - accuracy: 0.4967\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 6s 189ms/step - loss: 2.9708 - accuracy: 0.4994\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 2.9430 - accuracy: 0.5037\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 2.9139 - accuracy: 0.5072\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 7s 197ms/step - loss: 2.8855 - accuracy: 0.5099\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 2.8572 - accuracy: 0.5142\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 2.8310 - accuracy: 0.5164\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 7s 209ms/step - loss: 2.8026 - accuracy: 0.5201\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 2.7732 - accuracy: 0.5235\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 7s 211ms/step - loss: 2.7459 - accuracy: 0.5277\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 7s 215ms/step - loss: 2.7173 - accuracy: 0.5296\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 7s 214ms/step - loss: 2.6930 - accuracy: 0.5324\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 7s 214ms/step - loss: 2.6639 - accuracy: 0.5362\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 7s 213ms/step - loss: 2.6362 - accuracy: 0.5396\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 7s 207ms/step - loss: 2.6091 - accuracy: 0.5431\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 2.5864 - accuracy: 0.5447\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 2.5570 - accuracy: 0.5485\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 2.5308 - accuracy: 0.5512\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 7s 206ms/step - loss: 2.5059 - accuracy: 0.5534\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 7s 218ms/step - loss: 2.4806 - accuracy: 0.5576\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 2.4565 - accuracy: 0.5606\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 7s 210ms/step - loss: 2.4289 - accuracy: 0.5643\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 2.4057 - accuracy: 0.5673\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 2.3807 - accuracy: 0.5715\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 2.3553 - accuracy: 0.5738\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 2.3311 - accuracy: 0.5766\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 2.3070 - accuracy: 0.5797\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 2.2840 - accuracy: 0.5818\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 2.2581 - accuracy: 0.5858\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 2.2359 - accuracy: 0.5883\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 2.2126 - accuracy: 0.5919\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 2.1909 - accuracy: 0.5945\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 2.1644 - accuracy: 0.5980\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 2.1442 - accuracy: 0.6010\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 2.1223 - accuracy: 0.6028\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 2.0985 - accuracy: 0.6076\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 2.0758 - accuracy: 0.6100\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 2.0533 - accuracy: 0.6132\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 2.0339 - accuracy: 0.6150\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 2.0100 - accuracy: 0.6177\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.9887 - accuracy: 0.6216\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.9683 - accuracy: 0.6239\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 1.9458 - accuracy: 0.6281\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.9272 - accuracy: 0.6288\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.9042 - accuracy: 0.6336\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.8842 - accuracy: 0.6362\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 1.8647 - accuracy: 0.6386\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.8443 - accuracy: 0.6426\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.8273 - accuracy: 0.6441\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.8040 - accuracy: 0.6478\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.7838 - accuracy: 0.6509\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.7671 - accuracy: 0.6538\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.7464 - accuracy: 0.6563\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.7264 - accuracy: 0.6593\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 1.7079 - accuracy: 0.6621\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.6887 - accuracy: 0.6665\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.6697 - accuracy: 0.6681\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.6516 - accuracy: 0.6709\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.6337 - accuracy: 0.6748\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 1.6165 - accuracy: 0.6772\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 1.5968 - accuracy: 0.6802\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.5790 - accuracy: 0.6821\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 7s 207ms/step - loss: 1.5620 - accuracy: 0.6860\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.5458 - accuracy: 0.6880\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.5296 - accuracy: 0.6907\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.5098 - accuracy: 0.6949\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.4940 - accuracy: 0.6964\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.4800 - accuracy: 0.6987\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.4601 - accuracy: 0.7020\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.4442 - accuracy: 0.7046\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.4303 - accuracy: 0.7065\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 1.4122 - accuracy: 0.7101\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 1.3985 - accuracy: 0.7122\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.3819 - accuracy: 0.7156\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.3668 - accuracy: 0.7186\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.3517 - accuracy: 0.7193\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.3377 - accuracy: 0.7236\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.3208 - accuracy: 0.7260\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.3087 - accuracy: 0.7278\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.2936 - accuracy: 0.7306\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 1.2786 - accuracy: 0.7336\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.2647 - accuracy: 0.7354\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.2513 - accuracy: 0.7375\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.2372 - accuracy: 0.7413\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 7s 206ms/step - loss: 1.2230 - accuracy: 0.7428\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 1.2118 - accuracy: 0.7439\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.1974 - accuracy: 0.7463\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.1851 - accuracy: 0.7488\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.1697 - accuracy: 0.7525\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.1560 - accuracy: 0.7536\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.1437 - accuracy: 0.7564\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.1350 - accuracy: 0.7574\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.1199 - accuracy: 0.7604\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.1066 - accuracy: 0.7621\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.0972 - accuracy: 0.7633\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.0835 - accuracy: 0.7657\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.0709 - accuracy: 0.7684\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.0607 - accuracy: 0.7700\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.0480 - accuracy: 0.7722\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.0369 - accuracy: 0.7747\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.0250 - accuracy: 0.7762\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.0147 - accuracy: 0.7785\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.0030 - accuracy: 0.7796\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 7s 208ms/step - loss: 0.9929 - accuracy: 0.7826\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 7s 209ms/step - loss: 0.9804 - accuracy: 0.7860\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 7s 207ms/step - loss: 0.9707 - accuracy: 0.7864\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 7s 213ms/step - loss: 0.9593 - accuracy: 0.7889\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.9508 - accuracy: 0.7900\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.9390 - accuracy: 0.7933\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 0.9297 - accuracy: 0.7950\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.9192 - accuracy: 0.7972\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.9101 - accuracy: 0.7979\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 7s 202ms/step - loss: 0.9004 - accuracy: 0.8004\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 0.8897 - accuracy: 0.8013\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 0.8801 - accuracy: 0.8047\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.8707 - accuracy: 0.8052\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.8619 - accuracy: 0.8072\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.8516 - accuracy: 0.8084\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.8439 - accuracy: 0.8099\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.8358 - accuracy: 0.8122\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.8253 - accuracy: 0.8128\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.8177 - accuracy: 0.8150\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.8085 - accuracy: 0.8167\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.7998 - accuracy: 0.8184\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 0.7923 - accuracy: 0.8199\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.7825 - accuracy: 0.8212\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.7758 - accuracy: 0.8223\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.7684 - accuracy: 0.8243\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.7588 - accuracy: 0.8258\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.7516 - accuracy: 0.8275\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.7430 - accuracy: 0.8300\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 7s 211ms/step - loss: 0.7365 - accuracy: 0.8311\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 0.7291 - accuracy: 0.8311\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.7202 - accuracy: 0.8337\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.7148 - accuracy: 0.8345\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.7059 - accuracy: 0.8371\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.6988 - accuracy: 0.8370\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.6923 - accuracy: 0.8389\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 0.6854 - accuracy: 0.8391\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 0.6781 - accuracy: 0.8408\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.6702 - accuracy: 0.8432\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 0.6638 - accuracy: 0.8442\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 0.6590 - accuracy: 0.8443\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.6517 - accuracy: 0.8466\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.6459 - accuracy: 0.8469\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 0.6382 - accuracy: 0.8490\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.6338 - accuracy: 0.8498\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.6253 - accuracy: 0.8511\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.6214 - accuracy: 0.8509\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 0.6131 - accuracy: 0.8543\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.6080 - accuracy: 0.8552\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.6034 - accuracy: 0.8542\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 0.5959 - accuracy: 0.8570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x248e083cbe0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([english_padded_arr, marathi_padded_arr], decoder_output_data, epochs=200, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36120134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_refrece_model():\n",
    "    encoder_model_refrence = Model(encoder_input, encoder_states)\n",
    "    \n",
    "    decoder_state_h = Input(shape=(128, ))\n",
    "    decoder_state_c = Input(shape=(128, ))\n",
    "    decoder_inputs_states = [decoder_state_h, decoder_state_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embeding, initial_state=decoder_inputs_states)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model_refrence = Model([decoder_input] + decoder_inputs_states,\n",
    "                                   [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model_refrence, decoder_model_refrence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7c59a",
   "metadata": {},
   "source": [
    "# Transform Sentence To Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fdcf11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_token(sen):\n",
    "    words = sen.lower().split()\n",
    "    token_list = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            token_list.append(eng_word_dict[word])\n",
    "        except:\n",
    "            print(\"THe sentence is not recognize \")\n",
    "            run()\n",
    "    return pad_sequences([token_list], maxlen=max_eng, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "723954e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    enc_model, dec_model = make_refrece_model()\n",
    "\n",
    "#     enc_model.save(r\"D:\\Courses language programming\\9_Big Projects\\14 - Machine Translation\\mar-eng\\encoder_model\")\n",
    "#     enc_model.save(r\"D:\\Courses language programming\\9_Big Projects\\14 - Machine Translation\\mar-eng\\decoder_model\")\n",
    "\n",
    "    for sen in range(english_padded_arr.shape[0]):\n",
    "        states_values = enc_model.predict(str_to_token(input(\"Enter an English Sentence:  \")))\n",
    "\n",
    "        empty_target = np.zeros((1, 1))\n",
    "        empty_target[0, 0] = mar_word_dict[\"start\"]\n",
    "        stopping_condition = False\n",
    "        decoded_translation = \"\"\n",
    "        while not stopping_condition:\n",
    "            dec_output, h, c = dec_model.predict([empty_target] + states_values)\n",
    "            sampled_word_index = np.argmax(dec_output[0, -1, :])\n",
    "            sampled_word = None\n",
    "            for word, index in mar_word_dict.items():\n",
    "                if sampled_word_index == index:\n",
    "                    decoded_translation += \" \" + word\n",
    "                    sampled_word = word\n",
    "                if sampled_word == \"end\" or len(decoded_translation.split()) > max_mar:\n",
    "                    stopping_condition = True\n",
    "\n",
    "            empty_target = np.zeros((1, 1))\n",
    "            empty_target[0, 0] = sampled_word_index\n",
    "            states_values = [h, c]\n",
    "\n",
    "        print(decoded_translation[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00c1cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d9545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
