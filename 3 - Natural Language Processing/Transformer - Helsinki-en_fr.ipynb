{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-09-01T00:08:53.662651Z",
     "iopub.status.busy": "2024-09-01T00:08:53.661990Z",
     "iopub.status.idle": "2024-09-01T00:09:08.835170Z",
     "shell.execute_reply": "2024-09-01T00:09:08.834023Z",
     "shell.execute_reply.started": "2024-09-01T00:08:53.662609Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m858.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: portalocker, sacrebleu, evaluate\n",
      "Successfully installed evaluate-0.4.2 portalocker-2.10.1 sacrebleu-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets numpy evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:09:08.837513Z",
     "iopub.status.busy": "2024-09-01T00:09:08.837185Z",
     "iopub.status.idle": "2024-09-01T00:09:28.820730Z",
     "shell.execute_reply": "2024-09-01T00:09:28.819953Z",
     "shell.execute_reply.started": "2024-09-01T00:09:08.837478Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments,AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "from transformers import MarianMTModel, MarianTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://huggingface.co/datasets/Helsinki-NLP/opus_books\n",
    "### https://huggingface.co/Helsinki-NLP/opus-mt-tc-big-en-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:09:28.822309Z",
     "iopub.status.busy": "2024-09-01T00:09:28.821766Z",
     "iopub.status.idle": "2024-09-01T00:09:31.258377Z",
     "shell.execute_reply": "2024-09-01T00:09:31.257512Z",
     "shell.execute_reply.started": "2024-09-01T00:09:28.822276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbe72f5f0ac4807b376f5e31d1bad72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fd767cc1614ae290b70ce3bfc6a0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d282dc9ae35b4880ae27314eecb2b40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/127085 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 127085\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Helsinki-NLP/opus_books\", \"en-fr\")\n",
    "ds = ds.remove_columns('id')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:09:31.260673Z",
     "iopub.status.busy": "2024-09-01T00:09:31.260330Z",
     "iopub.status.idle": "2024-09-01T00:09:31.362472Z",
     "shell.execute_reply": "2024-09-01T00:09:31.361510Z",
     "shell.execute_reply.started": "2024-09-01T00:09:31.260639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 101668\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 25417\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds['train'].train_test_split(train_size=0.8)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:09:31.363881Z",
     "iopub.status.busy": "2024-09-01T00:09:31.363549Z",
     "iopub.status.idle": "2024-09-01T00:09:31.372755Z",
     "shell.execute_reply": "2024-09-01T00:09:31.371783Z",
     "shell.execute_reply.started": "2024-09-01T00:09:31.363849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'en': '\"I could not find them; they did not come.\"',\n",
       "  'fr': '-- Je ne les avais pas trouvés, ils ne sont pas venus.'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:09:31.374330Z",
     "iopub.status.busy": "2024-09-01T00:09:31.373960Z",
     "iopub.status.idle": "2024-09-01T00:09:51.819241Z",
     "shell.execute_reply": "2024-09-01T00:09:51.818305Z",
     "shell.execute_reply.started": "2024-09-01T00:09:31.374298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e59b809c97449daf843a5f2143a984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/337 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9191277bad6d4f56bac5898aa986f167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e605449e446a4c15bc2547026c8e3c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/820k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79801dc72e39410ebb1752560a04eb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.33M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd4f8a9746b49cbb1802a33627e4629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8b3b78b4bb44818caf5e159b7ef61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e443b2bbc34d428e4a285c2dbea2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/461M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bad09a52ca442c94e503f0e08d76d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_checkpionts = 'Helsinki-NLP/opus-mt-tc-big-en-fr'\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpionts)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpionts)\n",
    "\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_checkpionts)\n",
    "model = MarianMTModel.from_pretrained(model_checkpionts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing In Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:09:51.821085Z",
     "iopub.status.busy": "2024-09-01T00:09:51.820738Z",
     "iopub.status.idle": "2024-09-01T00:09:52.277787Z",
     "shell.execute_reply": "2024-09-01T00:09:52.276824Z",
     "shell.execute_reply.started": "2024-09-01T00:09:51.821047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'en': 'Voici le traité que je vous propose : si vous daignez y consentir, je ne serai pas votre maîtresse pour un instant fugitif, et en vertu d’un serment extorqué par la peur, mais je consacrerai tous les instants de ma vie à faire votre félicité, je serai toujours ce que j’ai été depuis quatre mois, et peut-être l’amour viendra-t-il couronner l’amitié.',\n",
       "  'fr': 'This is the compact that I propose; if you deign to consent to it, I shall not be your mistress for a fleeting instant, and by virtue of an oath extorted by fear, but I shall consecrate every moment of my life to procuring your happiness, I shall be always what I have been for the last four months, and perhaps love will come to crown friendship.'},\n",
       " {'en': 'This boat was iron-plated.',\n",
       "  'fr': 'Ce canot était fait en tôle boulonnée.'},\n",
       " {'en': 'Their object in lighting a fire was only to enable them to withstand the cold temperature of the night, as it was not employed in cooking the bird, which Neb kept for the next day.',\n",
       "  'fr': \"Ce feu n'était destiné qu'à combattre la température un peu froide de la nuit, et il ne fut pas employé à la cuisson du faisan, que Nab réservait pour le lendemain.\"}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test']['translation'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:09:52.279294Z",
     "iopub.status.busy": "2024-09-01T00:09:52.279002Z",
     "iopub.status.idle": "2024-09-01T00:09:52.285387Z",
     "shell.execute_reply": "2024-09-01T00:09:52.284392Z",
     "shell.execute_reply.started": "2024-09-01T00:09:52.279264Z"
    }
   },
   "outputs": [],
   "source": [
    "source_lan = 'en'\n",
    "target_lan = 'fr'\n",
    "prefix = 'translate English to Frensh: '\n",
    "\n",
    "def preprocessing(data):\n",
    "    inputs = [example[source_lan] for example in data['translation']]\n",
    "    target = [example[target_lan] for example in data['translation']]\n",
    "    model_inputs = tokenizer(inputs, text_target=target, return_tensors=\"pt\", padding=True,\n",
    "                             truncation=True)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:09:52.287124Z",
     "iopub.status.busy": "2024-09-01T00:09:52.286652Z",
     "iopub.status.idle": "2024-09-01T00:11:29.636055Z",
     "shell.execute_reply": "2024-09-01T00:11:29.634954Z",
     "shell.execute_reply.started": "2024-09-01T00:09:52.287063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c57229ae37145809b57a5c12a43c3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/101668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55b5d06550a4c8eb2c04f25c79e14c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(preprocessing, batched=True)\n",
    "# ds['test'].map(preprocessing, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:11:29.640405Z",
     "iopub.status.busy": "2024-09-01T00:11:29.639517Z",
     "iopub.status.idle": "2024-09-01T00:11:29.647904Z",
     "shell.execute_reply": "2024-09-01T00:11:29.645473Z",
     "shell.execute_reply.started": "2024-09-01T00:11:29.640352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 101668\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 25417\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CollectionSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:11:29.649487Z",
     "iopub.status.busy": "2024-09-01T00:11:29.649145Z",
     "iopub.status.idle": "2024-09-01T00:11:29.896389Z",
     "shell.execute_reply": "2024-09-01T00:11:29.895231Z",
     "shell.execute_reply.started": "2024-09-01T00:11:29.649448Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_checkpionts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:11:29.898419Z",
     "iopub.status.busy": "2024-09-01T00:11:29.897876Z",
     "iopub.status.idle": "2024-09-01T00:11:30.669495Z",
     "shell.execute_reply": "2024-09-01T00:11:30.668511Z",
     "shell.execute_reply.started": "2024-09-01T00:11:29.898347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041e19fc12a94fe5b874ae28d5c5f5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:11:30.671647Z",
     "iopub.status.busy": "2024-09-01T00:11:30.670770Z",
     "iopub.status.idle": "2024-09-01T00:11:30.680792Z",
     "shell.execute_reply": "2024-09-01T00:11:30.679976Z",
     "shell.execute_reply.started": "2024-09-01T00:11:30.671578Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:19:28.554147Z",
     "iopub.status.busy": "2024-09-01T00:19:28.553751Z",
     "iopub.status.idle": "2024-09-01T00:19:28.605705Z",
     "shell.execute_reply": "2024-09-01T00:19:28.604575Z",
     "shell.execute_reply.started": "2024-09-01T00:19:28.554110Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./Helsinki-mt-en-fr\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    "    warmup_steps=2000,\n",
    "    logging_steps=2000, save_steps=4000\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "model=model,\n",
    "args=args,\n",
    "tokenizer=tokenizer,\n",
    "data_collator=data_collator,\n",
    "compute_metrics=compute_metrics,\n",
    "train_dataset=ds['train'],\n",
    "eval_dataset=ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:19:29.487302Z",
     "iopub.status.busy": "2024-09-01T00:19:29.486408Z",
     "iopub.status.idle": "2024-09-01T03:19:44.891634Z",
     "shell.execute_reply": "2024-09-01T03:19:44.890757Z",
     "shell.execute_reply.started": "2024-09-01T00:19:29.487262Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6355' max='6355' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6355/6355 3:00:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.941300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.199300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[53016]], 'forced_eos_token_id': 43311}\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[53016]], 'forced_eos_token_id': 43311}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6355, training_loss=0.4352935178743208, metrics={'train_runtime': 10814.6754, 'train_samples_per_second': 9.401, 'train_steps_per_second': 0.588, 'total_flos': 4.439994884318822e+16, 'train_loss': 0.4352935178743208, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
